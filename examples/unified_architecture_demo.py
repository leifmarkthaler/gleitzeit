#!/usr/bin/env python3
"""
Unified Socket.IO Architecture Demo

Demonstrates the new unified architecture where ALL tasks (LLM, Python, external)
are handled via Socket.IO services, making Gleitzeit a pure orchestrator.
"""

import asyncio
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from gleitzeit_cluster import GleitzeitCluster
from gleitzeit_cluster.decorators import gleitzeit_task


# ============================================
# Define Python tasks with decorators
# ============================================

@gleitzeit_task(category="data")
def preprocess_document(document: str) -> dict:
    """Extract key information from document"""
    lines = document.strip().split('\n')
    word_count = len(document.split())
    
    # Extract potential topics (simple keyword matching)
    topics = []
    for line in lines:
        if any(keyword in line.lower() for keyword in ['report', 'analysis', 'revenue', 'growth']):
            topics.append(line.strip())
    
    return {
        "line_count": len(lines),
        "word_count": word_count,
        "topics": topics[:5],  # Top 5 topics
        "processed_at": "python_service"
    }


@gleitzeit_task(category="formatting")
def format_multi_provider_results(results: dict) -> str:
    """Format results from multiple LLM providers"""
    
    report = "# Multi-Provider LLM Analysis Report\n\n"
    
    for provider, result in results.items():
        report += f"## {provider.title()} Analysis\n"
        report += f"{result}\n\n"
    
    report += "---\n"
    report += "Generated by Gleitzeit Unified Architecture\n"
    
    return report


# ============================================
# Unified Architecture Workflow
# ============================================

async def unified_architecture_demo():
    """
    Demonstrate unified architecture with multiple providers
    """
    
    print("ğŸŒ Unified Socket.IO Architecture Demo")
    print("=" * 50)
    print("All tasks (LLM + Python) route through Socket.IO services")
    print()
    
    # Create cluster with unified architecture enabled
    cluster = GleitzeitCluster(
        # Enable unified architecture
        use_unified_socketio_architecture=True,
        auto_start_internal_llm_service=True,
        
        # Also enable external Python execution
        use_external_python_executor=True, 
        auto_start_python_executor=True,
        
        # Simplified for demo
        enable_redis=False,
        enable_real_execution=False,
        auto_start_services=False
    )
    
    # Create workflow
    workflow = cluster.create_workflow("Unified Architecture Demo")
    
    # Sample business document
    document = """
    Q3 Financial Report
    Revenue increased 25% year-over-year
    New market expansion in Europe completed
    R&D investment doubled for AI initiatives
    Customer satisfaction improved to 4.8/5
    """
    
    print(f"ğŸ“„ Sample Document:\n{document}")
    print(f"\nğŸ—ï¸ Building workflow with unified architecture...")
    
    # Step 1: Python preprocessing (via Socket.IO)
    preprocess = workflow.add_external_task(
        name="Preprocess Document",
        external_task_type="python_execution",
        service_name="Python Tasks",
        external_parameters={
            "function_name": "preprocess_document",
            "args": [document],
            "kwargs": {}
        }
    )
    
    # Step 2: Multiple LLM providers analyze the same data
    
    # Internal Ollama service
    internal_analysis = workflow.add_text_task(
        name="Internal Analysis",
        prompt="Analyze this business document: {{Preprocess Document.result}}",
        model="llama3",
        provider="internal",  # Routes to Internal LLM Service
        dependencies=["Preprocess Document"]
    )
    
    # External OpenAI service (mock for demo)
    openai_analysis = workflow.add_text_task(
        name="OpenAI Analysis", 
        prompt="Provide strategic insights: {{Preprocess Document.result}}",
        model="gpt-4",
        provider="openai",  # Routes to OpenAI Service
        dependencies=["Preprocess Document"]
    )
    
    # External Anthropic service (mock for demo)
    claude_analysis = workflow.add_text_task(
        name="Claude Analysis",
        prompt="Evaluate risks and opportunities: {{Preprocess Document.result}}",
        model="claude-3-sonnet",
        provider="anthropic",  # Routes to Anthropic Service
        dependencies=["Preprocess Document"]
    )
    
    # Step 3: Python task to combine all LLM results (via Socket.IO)
    final_report = workflow.add_external_task(
        name="Format Final Report",
        external_task_type="python_execution",
        service_name="Python Tasks",
        external_parameters={
            "function_name": "format_multi_provider_results",
            "args": [{
                "internal": "{{Internal Analysis.result}}",
                "openai": "{{OpenAI Analysis.result}}",
                "claude": "{{Claude Analysis.result}}"
            }],
            "kwargs": {}
        },
        dependencies=["Internal Analysis", "OpenAI Analysis", "Claude Analysis"]
    )
    
    print(f"âœ… Created unified workflow with {len(workflow.tasks)} tasks:")
    
    # Show task routing
    for task in workflow.tasks.values():
        if task.task_type.value.startswith("external"):
            service = task.parameters.service_name
            task_type = task.parameters.external_task_type
            deps = f" (deps: {', '.join(task.dependencies)})" if task.dependencies else ""
            print(f"   ğŸ“¡ {task.name}: {service} â†’ {task_type}{deps}")
        else:
            deps = f" (deps: {', '.join(task.dependencies)})" if task.dependencies else ""
            print(f"   ğŸ”— {task.name}: Direct â†’ {task.task_type}{deps}")
    
    # Show architecture benefits
    print(f"\nğŸ›ï¸ Unified Architecture Benefits:")
    print(f"   ğŸ¯ Pure Orchestrator: Gleitzeit only coordinates, never executes")
    print(f"   ğŸ”„ Unified Protocol: All tasks use Socket.IO communication")
    print(f"   ğŸ“Š Unified Monitoring: All services appear in single dashboard")
    print(f"   ğŸ”§ Flexible Providers: Mix internal Ollama + external APIs")
    print(f"   ğŸ“ˆ Independent Scaling: Each service scales separately")
    
    return workflow


async def demonstrate_provider_flexibility():
    """Show how easy it is to mix different providers"""
    
    print("\nğŸ­ Provider Flexibility Demo")
    print("=" * 35)
    
    # Create workflow with mixed providers
    cluster = GleitzeitCluster(
        use_unified_socketio_architecture=True,
        enable_redis=False,
        enable_real_execution=False,
        auto_start_services=False
    )
    
    workflow = cluster.create_workflow("Multi-Provider Workflow")
    
    prompt = "Explain quantum computing in simple terms"
    
    # Same prompt, different providers
    providers = [
        ("llama3", "internal", "Internal LLM Service"),
        ("gpt-4", "openai", "OpenAI Service"),
        ("claude-3", "anthropic", "Anthropic Service"),
        ("mock-model", "mock", "Mock LLM Service")
    ]
    
    print("ğŸ“‹ Adding tasks for different providers:")
    
    for model, provider, service_name in providers:
        task = workflow.add_text_task(
            name=f"{provider.title()} Response",
            prompt=prompt,
            model=model,
            provider=provider
        )
        
        print(f"   ğŸ¤– {provider:>10}: {model:>15} â†’ {service_name}")
        
        # Verify routing
        assert task.task_type.value.startswith("external")
        assert task.parameters.service_name == service_name
        assert task.parameters.external_parameters["model"] == model
        assert task.parameters.external_parameters["provider"] == provider
    
    print(f"\nâœ… All {len(workflow.tasks)} tasks route through Socket.IO services")
    print("   Same API, different execution paths!")
    
    return workflow


async def show_architecture_comparison():
    """Show old vs new architecture"""
    
    print("\nğŸ“Š Architecture Comparison")
    print("=" * 30)
    
    # Old architecture
    print("ğŸ”¹ OLD: Mixed execution model")
    cluster_old = GleitzeitCluster(
        use_unified_socketio_architecture=False,
        enable_redis=False,
        enable_real_execution=False
    )
    workflow_old = cluster_old.create_workflow("Old Architecture")
    
    old_llm = workflow_old.add_text_task("LLM Task", "Test prompt")
    old_python = workflow_old.add_python_task("Python Task", "my_function")
    
    print(f"   LLM Task:    {old_llm.task_type} (direct execution)")
    print(f"   Python Task: {old_python.task_type} (direct execution)")
    
    # New architecture
    print("\nğŸ”¹ NEW: Unified Socket.IO model")
    cluster_new = GleitzeitCluster(
        use_unified_socketio_architecture=True,
        use_external_python_executor=True,
        enable_redis=False,
        enable_real_execution=False,
        auto_start_services=False
    )
    workflow_new = cluster_new.create_workflow("New Architecture")
    
    new_llm = workflow_new.add_text_task("LLM Task", "Test prompt")
    new_python = workflow_new.add_python_task("Python Task", "my_function")
    
    print(f"   LLM Task:    {new_llm.task_type} â†’ {new_llm.parameters.service_name}")
    print(f"   Python Task: {new_python.task_type} â†’ {new_python.parameters.service_name}")
    
    print("\nğŸ¯ Benefits of Unified Architecture:")
    print("   âœ… Pure orchestrator (no execution logic)")
    print("   âœ… Uniform communication protocol")
    print("   âœ… Uniform monitoring and metrics")
    print("   âœ… Easy to add new providers")
    print("   âœ… Independent service scaling")
    print("   âœ… Better fault isolation")


async def main():
    """Main demonstration"""
    
    try:
        # Run demonstrations
        await unified_architecture_demo()
        await demonstrate_provider_flexibility()
        await show_architecture_comparison()
        
        print("\nğŸ‰ Unified Architecture Demo Complete!")
        print("\nâœ… Key Achievements:")
        print("   ğŸ›ï¸ Pure orchestrator architecture")
        print("   ğŸ”„ All tasks via Socket.IO (LLM + Python + External)")
        print("   ğŸ¯ Provider flexibility (internal Ollama + external APIs)")
        print("   ğŸ“Š Unified monitoring and management")
        print("   ğŸš€ Clean, scalable, extensible design")
        
        print("\nğŸ“‹ To run with real services:")
        print("   1. Start cluster: python -c 'import gleitzeit_cluster; ...'")
        print("   2. Start internal LLM: python services/internal_llm_service.py")
        print("   3. Start external providers: python services/external_llm_providers.py")
        print("   4. Start Python tasks: python -c 'from gleitzeit_cluster.decorators import start_task_service; ...'")
        
        return True
        
    except Exception as e:
        print(f"\nğŸ’¥ Demo failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    print(f"\n{'ğŸ¯ UNIFIED ARCHITECTURE READY' if success else 'âŒ ISSUES FOUND'}")
    sys.exit(0 if success else 1)