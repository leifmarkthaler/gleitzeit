{
  "timestamp": "2025-08-14T11:30:06.624858",
  "summary": {
    "total_tests": 14,
    "passed_tests": 11,
    "failed_tests": 3,
    "total_time": 8.68349575996399
  },
  "results": [
    {
      "name": "tests/test_events.py - Event System Architecture",
      "success": true,
      "output": "Results: 15/15 tests passed (100.0%)",
      "error": "",
      "execution_time": 0.12664127349853516,
      "timestamp": "2025-08-14T11:29:58.066685"
    },
    {
      "name": "tests/test_jsonrpc.py - JSON-RPC 2.0 Protocol",
      "success": true,
      "output": "Results: 20/24 tests passed (83.3%)",
      "error": "ethod()\n             ^^^^^^^^^^^^^\n  File \"/Users/leifmarkthaler/gleitzeit/gleitzeit2/gleitzeit/old/gleitzeit_v4/tests/test_jsonrpc.py\", line 738, in test_error_handling_flow\n    assert error_response.error.code == ErrorCode.TASK_VALIDATION_ERROR.value\n                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/enum.py\", line 783, in __getattr__\n    raise AttributeError(name) from None\nAttributeError: TASK_VALIDATION_ERROR\n",
      "execution_time": 0.18255996704101562,
      "timestamp": "2025-08-14T11:29:58.249433"
    },
    {
      "name": "tests/test_scheduler.py - Event-driven Scheduling",
      "success": true,
      "output": "Results: 17/17 tests passed (100.0%)",
      "error": "Failed to emit event ScheduledEventType.TASK_RETRY_1755156599.445565: Emission failed!\nFailed to emit scheduled event ScheduledEventType.TASK_RETRY_1755156599.445565: Emission failed!\nError in scheduler loop: Process failed!\n",
      "execution_time": 2.4504292011260986,
      "timestamp": "2025-08-14T11:30:00.700062"
    },
    {
      "name": "tests/test_protocol_validation.py - Protocol Validation & Method Routing",
      "success": true,
      "output": "Results: 24/25 tests passed (96.0%)",
      "error": "it/gleitzeit2/gleitzeit/old/gleitzeit_v4/tests/test_protocol_validation.py\", line 1222, in run_protocol_validation_tests\n    result = test_method()\n             ^^^^^^^^^^^^^\n  File \"/Users/leifmarkthaler/gleitzeit/gleitzeit2/gleitzeit/old/gleitzeit_v4/tests/test_protocol_validation.py\", line 641, in test_method_call_validation\n    assert False, f\"Invalid method call accepted: {method_name}, {params}\"\nAssertionError: Invalid method call accepted: calculate, {'operation': 'add', 'operands': [1]}\n",
      "execution_time": 0.18040919303894043,
      "timestamp": "2025-08-14T11:30:00.880732"
    },
    {
      "name": "tests/test_provider_registry.py - Provider Registry & Load Balancing",
      "success": true,
      "output": "Results: 12/12 tests passed (100.0%)",
      "error": "",
      "execution_time": 0.15371489524841309,
      "timestamp": "2025-08-14T11:30:01.034590"
    },
    {
      "name": "tests/test_protocol_provider_executor_simple.py - Protocol/Provider Framework",
      "success": true,
      "output": "Results: 6/6 tests passed (100.0%)",
      "error": "",
      "execution_time": 0.04573202133178711,
      "timestamp": "2025-08-14T11:30:01.080426"
    },
    {
      "name": "tests/test_cli_simple.py - Basic CLI Functionality",
      "success": true,
      "output": "\ud83d\udcca Success Rate: 100.0%",
      "error": "",
      "execution_time": 0.24332189559936523,
      "timestamp": "2025-08-14T11:30:01.323865"
    },
    {
      "name": "tests/test_cli_integration.py - CLI Integration & Workflow Execution",
      "success": true,
      "output": "Results: 4/4 tests passed (100.0%)",
      "error": "<aiohttp.client_proto.ResponseHandler object at 0x1078b04b0>, 280496.261197333)])']\nconnector: <aiohttp.connector.TCPConnector object at 0x1078b7cd0>\n2025-08-14 11:30:02,605 - ERROR - Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x1078e18d0>\n2025-08-14 11:30:02,605 - ERROR - Unclosed connector\nconnections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x1078b0b40>, 280497.293618)])']\nconnector: <aiohttp.connector.TCPConnector object at 0x1078e1890>\n",
      "execution_time": 1.299170970916748,
      "timestamp": "2025-08-14T11:30:02.623182"
    },
    {
      "name": "tests/test_cli.py - Comprehensive CLI Features",
      "success": false,
      "output": "\ud83d\udcca Success Rate: 48.0%",
      "error": "iohttp.client_proto.ResponseHandler object at 0x1103c40c0>, 280498.66017075)])']\nconnector: <aiohttp.connector.TCPConnector object at 0x1103a1750>\n2025-08-14 11:30:03,973 - ERROR - Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x1103e0850>\n2025-08-14 11:30:03,973 - ERROR - Unclosed connector\nconnections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x1103c4280>, 280498.673325416)])']\nconnector: <aiohttp.connector.TCPConnector object at 0x1103e0810>\n",
      "execution_time": 1.3664813041687012,
      "timestamp": "2025-08-14T11:30:03.989807"
    },
    {
      "name": "tests/test_workflow_manager.py - Workflow Management",
      "success": true,
      "output": "\u2705 Success rate: 50.0%",
      "error": "",
      "execution_time": 0.15880703926086426,
      "timestamp": "2025-08-14T11:30:04.148752"
    },
    {
      "name": "tests/test_dependency_resolution.py - Dependency Resolution",
      "success": true,
      "output": "Results: 5/6 tests passed (83.3%)",
      "error": "4 11:30:04,337 - INFO - Initialized EventScheduler\n2025-08-14 11:30:04,337 - INFO - Initialized event-driven RetryManager\n2025-08-14 11:30:04,337 - INFO - Initialized DependencyTracker with max_attempts=3\n2025-08-14 11:30:04,337 - INFO - Initialized ExecutionEngine with max_concurrent_tasks=10\n2025-08-14 11:30:04,337 - INFO - Initialized DependencyResolver\nsys:1: RuntimeWarning: coroutine '_run_workflow' was never awaited\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "execution_time": 0.21287918090820312,
      "timestamp": "2025-08-14T11:30:04.361773"
    },
    {
      "name": "tests/test_sqlite_backend.py - SQLite Persistence Backend",
      "success": true,
      "output": "\n\ud83c\udf89 SQLITE BACKEND TEST PASSED!\n\u2705 Multi-backend architecture verified\n\u2705 SQLite persistence working perfectly\n\u2705 Identical functionality to Redis backend\n\u2705 Ready for single-node deployments\n",
      "error": "rking correctly:\nINFO:__main__:  \u2022 SQLite backend provides full persistence functionality\nINFO:__main__:  \u2022 Task execution works identically with SQLite and Redis\nINFO:__main__:  \u2022 Retry logic integrates properly with SQLite\nINFO:__main__:  \u2022 All backend interface methods implemented\nINFO:__main__:  \u2022 Statistics and queries working\nINFO:__main__:  \u2022 ACID properties and data integrity maintained\nINFO:__main__:  \u2022 Ready for production single-node deployments\nINFO:__main__:\u2713 Test cleanup completed\n",
      "execution_time": 2.1755752563476562,
      "timestamp": "2025-08-14T11:30:06.537515"
    },
    {
      "name": "tests/test_ollama_integration.py - Ollama LLM Integration",
      "success": false,
      "output": "=== Testing Gleitzeit V4 with Ollama Provider ===\n\n\u2717 Test failed: No module named 'gleitzeit_v4'\n\nCleaning up...\n\u2713 Cleanup completed\n\n\u274c Ollama test failed!\n",
      "error": "Traceback (most recent call last):\n  File \"/Users/leifmarkthaler/gleitzeit/gleitzeit2/gleitzeit/old/gleitzeit_v4/tests/test_ollama_integration.py\", line 34, in test_ollama_system\n    from gleitzeit_v4.server.central_server import CentralServer\nModuleNotFoundError: No module named 'gleitzeit_v4'\n",
      "execution_time": 0.0472562313079834,
      "timestamp": "2025-08-14T11:30:06.584949"
    },
    {
      "name": "tests/test_python_functions.py - Python Function Execution",
      "success": false,
      "output": "Python Function Test Results: 0/3 tests passed",
      "error": "nctions.py\", line 101, in test_custom_function_loading\n    from gleitzeit_v4.providers.python_function_provider import CustomFunctionProvider\nModuleNotFoundError: No module named 'gleitzeit_v4'\nTraceback (most recent call last):\n  File \"/Users/leifmarkthaler/gleitzeit/gleitzeit2/gleitzeit/old/gleitzeit_v4/tests/test_python_functions.py\", line 175, in test_python_function_workflow\n    from gleitzeit_v4.server.central_server import CentralServer\nModuleNotFoundError: No module named 'gleitzeit_v4'\n",
      "execution_time": 0.038340091705322266,
      "timestamp": "2025-08-14T11:30:06.623388"
    }
  ]
}